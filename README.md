# CUDA_Laboratory-work 
Samara University <br/>
HPC-2021
## Лабораторные работы по курсу "Высокопроизводительные вычисления".

## 0.[MatrixMul](https://github.com/Dark-MonkGI/Laboratory-work/blob/2acabac21aadec821bd6a56c421fa41be8692b89/0.%20MatrixMul/HPC_matrix_multi_GPU_ILia_Gr.ipynb)

**Задача:** Реализовать алгоритм перемножения матриц с применением технологии CUDA. <br/>
Реализация должна содержать 2 функции перемножения матриц: на CPU и на GPU
Отчет о проделанной лабораторной работе - это git-репозиторий с исходным кодом
реализации + описание проделанной работы там же в readme.
Необходимо описать реализацию, объяснив, что конкретно было распараллелено и
почему.
Провести эксперименты: перемножить матрицы разных размеров, посчитать
ускорение. Результаты привести в виде таблицы/графика.

**Язык:**  C++ или Python <br/> 
**Входные данные:**  Входные данные: 2 матрицы размером от 100х100 до 2000х2000 каждая. <br/> 
**Выходные данные:**  проверка корректности перемножения + время вычисления. <br/> 

##  **Техническое обеспечение** 
-  Процессор: `Intel(R) Xeon(R) CPU @ 2.30GHz`
-  Графический процессор: `b'Tesla K80'` 
-  Google Colaboratory <br/>
   compute capability: 3.7 
##  **Описание реализации** 

В данной лабораторной работе было произведено перемножение четырех пар матриц, поочередно на CPU и GPU, с применением технологии CUDA.
Выбранный размер матриц для вычислений: <br/>
- 100 х 100
- 300 х 300 
- 700 х 700 
- 1100 х 1100 <br/> 

Данная лабораторная работа выполнялась на языке программирования `"Python 3.7"` , с использованием библиотеки `Numba`.<br/>
> **Overview** <br/>
> Numba supports CUDA GPU programming by directly compiling a restricted subset of Python code into CUDA kernels and device functions following the CUDA execution model. Kernels
> written in Numba appear to have direct access to NumPy arrays. NumPy arrays are transferred between the CPU and the GPU automatically.

В основе данной программы лежат две функции: 
- `CPU_matmul` - функция перменожения матриц на CPU
- `GPU_matmul` - функция перремножения матриц на GPU, с декораторром `@cuda.jit` <br/>

Numba @jit декоратор в основном работает в двух режимах компиляции, nopythonрежим и objectрежим. Поведение nopythonрежим компиляции состоит в том, чтобы скомпилировать декорированную функцию так, чтобы она работала полностью без участия интерпретатора Python. Это рекомендуемый и лучший способ использования Numba @jit-декоратор, поскольку он ведет к лучшему представлению.

##  **Результаты вычислений** 
В таблице приведены результаты расчета случайно сгенерированных матриц на CPU и GPU соответственно: 
 	 № |Device|Time(hh:mm:ss)| Matrix_size | 
------------ | ------------- | ------------- |------------- |
50 | 0.004 | 0.113 | 
128 | 0.003 | 1.429 | 
 500 | 0.014 | 79.691 | 0.182 | 


<br/> 

 ##  **Заключение** 
 По результатам можно сделать вывод, что GPU действительно ускоряет процесс вычисления в разы, если сравнивать с вычислением на CPU. Также было замечено, что при малых размерах матриц скорости вычисления на CPU и GPU довольно одинаковы, а где-то CPU даже быстрее. <br/> 
 Для интереса были также получены результаты вычисления матриц с помощью встроенной функции  ```np.dot()```  и с помощью декоратора  ```@jit```  . Можно заметить, что использование декоратора, позволяет существенно увеличить скорость вычислений. <br/> 
 Ну и на десерт, были получены результаты перемножения матриц на чипе M1. Можно заметить, что скорость вычисления на чипе M1 примерно в раза быстрее, чем на CPU, предоставляемом Colabом, но этот результат по отношению с результатом вычислений на GPU, конечно же, оставляет желать лучшего. 
